{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1bb04648-7a9e-4903-98b5-be675e80bcc4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Hands-On Lab: Building Agent Systems with Databricks\n",
    "\n",
    "## Part 2 - Agent Evaluation\n",
    "Now that we've created an agent, how do we evaluate its performance?\n",
    "For the second part, we're going to create a product support agent so we can focus on evaluation.\n",
    "This agent will use a RAG approach to help answer questions about products using the product documentation.\n",
    "\n",
    "### 2.1 Define our new Agent and retriever tool\n",
    "- [**agent.py**]($./agent.py): An example Agent has been configured - first we'll explore this file and understand the building blocks\n",
    "- **Vector Search**: We've created a Vector Search endpoint that can be queried to find related documentation about a specific product.\n",
    "- **Create Retriever Function**: Define some properties about our retriever and package it so it can be called by our LLM.\n",
    "\n",
    "### 2.2 Create Evaluation Dataset\n",
    "- We've provided an example evaluation dataset - though you can also generate this [synthetically](https://www.databricks.com/blog/streamline-ai-agent-evaluation-with-new-synthetic-data-capabilities).\n",
    "\n",
    "### 2.3 Run MLflow.evaluate() \n",
    "- MLflow will take your evaluation dataset and test your agent's responses against it\n",
    "- LLM Judges will score the outputs and collect everything in a nice UI for review\n",
    "\n",
    "### 2.4 Make Needed Improvements and re-run Evaluations\n",
    "- Take feedback from our evaluation run and change retrieval settings\n",
    "- Run evals again and see the improvement!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0ce3f173-f173-4938-8b5f-b9a2d27f9aac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install -U -qqqq mlflow-skinny[databricks] langgraph==0.3.4 databricks-langchain databricks-agents uv\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1389c1c3-c101-4c2c-9bb0-6179d98ff07f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9e76a983-8d0b-4cb5-a7ba-3fbe2ed4c451",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from workshop_config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1e73c394-d933-4911-817d-374f48e5fab0",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Quick test to see if Agent works"
    }
   },
   "outputs": [],
   "source": [
    "from agent import AGENT\n",
    "\n",
    "AGENT.predict({\"messages\": [{\"role\": \"user\", \"content\": \"Can you give me troubleshooting tips for my Soundwave X5 Pro Headphones?\"}]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1bfb41b2-7726-4819-9631-706640ed78ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Log the `agent` as an MLflow model\n",
    "Log the agent as code from the [agent]($./agent) notebook. See [MLflow - Models from Code](https://mlflow.org/docs/latest/models.html#models-from-code)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d0571795-3c28-4119-ac96-5b02d874bfa5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Determine Databricks resources to specify for automatic auth passthrough at deployment time\n",
    "import mlflow\n",
    "from agent import tools, LLM_ENDPOINT_NAME\n",
    "from databricks_langchain import VectorSearchRetrieverTool\n",
    "from mlflow.models.resources import DatabricksFunction, DatabricksServingEndpoint\n",
    "from unitycatalog.ai.langchain.toolkit import UnityCatalogTool\n",
    "\n",
    "resources = [DatabricksServingEndpoint(endpoint_name=LLM_ENDPOINT_NAME)]\n",
    "for tool in tools:\n",
    "    if isinstance(tool, VectorSearchRetrieverTool):\n",
    "        resources.extend(tool.resources)\n",
    "    elif isinstance(tool, UnityCatalogTool):\n",
    "        resources.append(DatabricksFunction(function_name=tool.uc_function_name))\n",
    "\n",
    "input_example = {\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What color options are available for the Aria Modern Bookshelf?\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "with mlflow.start_run():\n",
    "    logged_agent_info = mlflow.pyfunc.log_model(\n",
    "        artifact_path=\"agent\",\n",
    "        python_model=\"agent.py\",\n",
    "        input_example=input_example,\n",
    "        resources=resources,\n",
    "        extra_pip_requirements=[\n",
    "            \"databricks-connect\"\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "70ffb4f6-34a5-4d68-9470-2ba179acd348",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load the model and create a prediction function\n",
    "logged_model_uri = f\"runs:/{logged_agent_info.run_id}/agent\"\n",
    "loaded_model = mlflow.pyfunc.load_model(logged_model_uri)\n",
    "\n",
    "def predict_wrapper(query):\n",
    "    # Format for chat-style models\n",
    "    model_input = {\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": query}]\n",
    "    }\n",
    "    response = loaded_model.predict(model_input)\n",
    "    \n",
    "    messages = response['messages']\n",
    "    return messages[-1]['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "41a41c30-a0ad-44b2-be6e-6e65abce9c71",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Evaluate the agent with [Agent Evaluation](https://docs.databricks.com/generative-ai/agent-evaluation/index.html)\n",
    "\n",
    "You can edit the requests or expected responses in your evaluation dataset and run evaluation as you iterate your agent, leveraging mlflow to track the computed quality metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "284b19cb-e0d1-43d7-84f1-978110c844d2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    \"request\": [\n",
    "        \"What color options are available for the Aria Modern Bookshelf?\",\n",
    "        \"How should I clean the Aurora Oak Coffee Table to avoid damaging it?\",\n",
    "        \"How should I clean the BlendMaster Elite 4000 after each use?\",\n",
    "        \"How many colors is the Flexi-Comfort Office Desk available in?\",\n",
    "        \"What sizes are available for the StormShield Pro Men's Weatherproof Jacket?\"\n",
    "    ],\n",
    "    \"expected_facts\": [\n",
    "        [\n",
    "            \"The Aria Modern Bookshelf is available in natural oak finish\",\n",
    "            \"The Aria Modern Bookshelf is available in black finish\",\n",
    "            \"The Aria Modern Bookshelf is available in white finish\"\n",
    "        ],\n",
    "        [\n",
    "            \"Use a soft, slightly damp cloth for cleaning.\",\n",
    "            \"Avoid using abrasive cleaners.\"\n",
    "        ],\n",
    "        [\n",
    "            \"The jar of the BlendMaster Elite 4000 should be rinsed.\",\n",
    "            \"Rinse with warm water.\",\n",
    "            \"The cleaning should take place after each use.\"\n",
    "        ],\n",
    "        [\n",
    "            \"The Flexi-Comfort Office Desk is available in three colors.\"\n",
    "        ],\n",
    "        [\n",
    "            \"The available sizes for the StormShield Pro Men's Weatherproof Jacket are Small, Medium, Large, XL, and XXL.\"\n",
    "        ]\n",
    "    ]\n",
    "}\n",
    "\n",
    "eval_dataset = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fcfae60e-cc29-4c1d-83c3-1a8de2cf3e53",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from mlflow.genai.scorers import Guidelines, Safety\n",
    "import mlflow.genai\n",
    "\n",
    "eval_data = []\n",
    "for request, facts in zip(data[\"request\"], data[\"expected_facts\"]):\n",
    "    eval_data.append({\n",
    "        \"inputs\": {\n",
    "            \"query\": request  # This matches the function parameter\n",
    "        },\n",
    "        \"expected_response\": \"\\n\".join(facts)\n",
    "    })\n",
    "\n",
    "# Define scorers for evaluation\n",
    "# These are guidelines that the LLM judge will use to evaluate responses\n",
    "\n",
    "# Define custom scorers tailored to product information evaluation\n",
    "scorers = [\n",
    "    Guidelines(\n",
    "        guidelines=\"\"\"Response must include ALL expected facts:\n",
    "        - Lists ALL colors/sizes if relevant (not partial lists)\n",
    "        - States EXACT specs if relevant (e.g., \"5 ATM\" not \"water resistant\")\n",
    "        - Includes ALL cleaning steps if asked\n",
    "        Fails if ANY fact is missing or wrong.\"\"\",\n",
    "        name=\"completeness_and_accuracy\",\n",
    "    ),\n",
    "    Guidelines(\n",
    "        guidelines=\"\"\"Response must be clear and direct:\n",
    "        - Answers the exact question asked\n",
    "        - Uses lists for options, steps for instructions\n",
    "        - No marketing fluff or extra background\n",
    "        - Concise but complete.\"\"\",\n",
    "        name=\"relevance_and_structure\",\n",
    "    ),\n",
    "    Guidelines(\n",
    "        guidelines=\"\"\"Response must stay on-topic:\n",
    "        - ONLY the product asked about\n",
    "        - NO made-up features or colors\n",
    "        - NO generic advice\n",
    "        - Uses exact product name from request.\"\"\",\n",
    "        name=\"product_specificity\",\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d53639e2-71dc-4382-9ced-50261c35f0ca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"Running evaluation...\")\n",
    "with mlflow.start_run():\n",
    "    results = mlflow.genai.evaluate(\n",
    "        data=eval_data,\n",
    "        predict_fn=predict_wrapper, \n",
    "        scorers=scorers,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "34749e50-8598-4abc-90c7-549402c31a3b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Lets go back to the [agent.py]($./agent.py) file and change our prompt to reduce marketing fluff."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "77386b42-4db1-4bce-b010-7154b51fa513",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Register the model to Unity Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4caa3695-e24f-49db-b1dc-533b74bf5b85",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.sdk import WorkspaceClient\n",
    "import os\n",
    "\n",
    "UC_MODEL_NAME = f\"{WORKSHOP_CATALOG}.{USER_SCHEMA}.product_agent\"\n",
    "\n",
    "# register the model to UC\n",
    "uc_registered_model_info = mlflow.register_model(model_uri=logged_agent_info.model_uri, name=UC_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e5436ff-f365-4466-acd0-5f47f81f19a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "# Retrieve the Databricks host URL\n",
    "workspace_url = spark.conf.get('spark.databricks.workspaceUrl')\n",
    "\n",
    "# Create HTML link to created agent\n",
    "html_link = f'<a href=\"https://{workspace_url}/explore/data/models/{WORKSHOP_CATALOG}/{USER_SCHEMA}/product_agent\" target=\"_blank\">Go to Unity Catalog to see Registered Agent</a>'\n",
    "display(HTML(html_link))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dd99d046-fef9-450d-b447-f4649b3c8885",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Deploy the agent\n",
    "\n",
    "##### Note: This is disabled for lab users but will work on your own workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee735e6e-2f1f-4998-b094-d7058523966f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks import agents\n",
    "\n",
    "# Deploy the model to the review app and a model serving endpoint\n",
    "\n",
    "# Disabled for the lab environment but we've deployed the agent already!\n",
    "\n",
    "# agents.deploy(\n",
    "#     uc_model_name,\n",
    "#     uc_registered_model_info.version,\n",
    "#     environment_vars={\n",
    "#         \"WORKSHOP_CATALOG\": WORKSHOP_CATALOG,\n",
    "#         \"WORKSHOP_SCHEMA\": WORKSHOP_SCHEMA,\n",
    "#         \"USER_SCHEMA\": USER_SCHEMA,\n",
    "#     },\n",
    "#     tags={\"endpointSource\": \"Agent Lab\"},\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "driver",
   "widgets": {
    "USER_SCHEMA": {
     "currentValue": "jesse_young",
     "nuid": "08eed743-8753-4cad-a14c-7c294b2c4b0f",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "jesse_young",
      "label": null,
      "name": "USER_SCHEMA",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "jesse_young",
      "label": null,
      "name": "USER_SCHEMA",
      "options": {
       "widgetType": "text",
       "autoCreated": false,
       "validationRegex": null
      }
     }
    },
    "WORKSHOP_CATALOG": {
     "currentValue": "jy_workshop",
     "nuid": "f9a1ffe0-513b-4bce-b61a-2678c4b2120d",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "jy_workshop",
      "label": null,
      "name": "WORKSHOP_CATALOG",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "jy_workshop",
      "label": null,
      "name": "WORKSHOP_CATALOG",
      "options": {
       "widgetType": "text",
       "autoCreated": false,
       "validationRegex": null
      }
     }
    },
    "WORKSHOP_SCHEMA": {
     "currentValue": "agents",
     "nuid": "2a648de2-9c9b-4c59-8c93-d0373cce347b",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "agents",
      "label": null,
      "name": "WORKSHOP_SCHEMA",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "agents",
      "label": null,
      "name": "WORKSHOP_SCHEMA",
      "options": {
       "widgetType": "text",
       "autoCreated": false,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
